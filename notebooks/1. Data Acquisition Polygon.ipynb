{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Alternate Method for Data Acquisition\n",
    "\n",
    "I noticed some issues with the previous dataset. Notably, the volume column contained many zero values. With enough incorrect values from the source data, errors can propogate to future pipeline steps. To correct this, I will instead use the Alpaca API which allows for historical data acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To acquire the data, an API key from [Alpaca](https://alpaca.markets/) is required. Alpaca provides an easy to use API for stock trading, market data acquisition, and backtesting. Some features require an authorized account, which is for now available only to U.S. citizens. To utilize the API  you must first generate two keys, a key ID and a secret key. This can be done on the Alpaca website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "key_id = None\n",
    "secret_key = None\n",
    "with open('../files/private/alpakey') as key_file:\n",
    "    keys = key_file.readlines()\n",
    "    key_id = keys[0].strip()\n",
    "    secret_key = keys[1].strip()\n",
    "    \n",
    "api_url = \"https://paper-api.alpaca.markets\"\n",
    "\n",
    "alpaca = tradeapi.REST(key_id, secret_key, api_url, api_version='v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'sp_500.json' contains a list of the stocks traded on the S&P 500, also known as the S&P 500 constituents. Some ETFs (Exchange Traded Funds) track multiple stocks and can be used to approximate the market as a whole. The SPY ETF tracks the S&P 500, a collection of stocks listed on the US markets. By combining stock data with overall market data, better predictions can be made that take into account market ups and downs. Other ETFs may work just as well, such as DIA (Dow Jones Industrial Average) or VUG (Vanguard). In my tests, they all performed similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../files/public/sp_500.json', 'r') as top_symbols:\n",
    "    symbols = json.load(top_symbols)\n",
    "    \n",
    "symbols.append('SPY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API lets you specify the timeperiod between each data point, the number of data points, and the starting or ending point. The results can be returned as a DataFrame for convenience. To train the model, data from as far back as 2007 will be acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165cc4196efc4be59428391985fc7744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_stocks = []\n",
    "for symbol in tqdm(symbols):\n",
    "    try:\n",
    "        stock = alpaca.polygon.historic_agg_v2(symbol, 1, 'day',\n",
    "                                               _from='2007-01-01', to='2020-07-01').df\n",
    "        stock['symbol'] = symbol\n",
    "        top_stocks.append(stock)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "\n",
    "# After the stocks have been retrieved, I concatenate them into a single DataFrame.        \n",
    "top_stocks = pd.concat(top_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stocks.reset_index(inplace=True)\n",
    "top_stocks.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'symbol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For backtesting the model, unseen data will need to be acquired. However, due to fluctuations in the market, not every year makes for balanced data. To avoid this, I will backtest using three sets of data. \n",
    "\n",
    "##### Backtest Set 1: 2008\n",
    "    \n",
    "The market crash of 2008 was one of the worst on record. I'll choose this year to test the model's performance in the face of a recession.\n",
    "    \n",
    "##### Backtest Set 2: 2011\n",
    "\n",
    "2011 was neither a good year or a bad year for the market. There was little difference between stock prices in January and December. I'll choose this year to test the model's performance in flat years.\n",
    "\n",
    "##### Backtest Set 3: 2013\n",
    "\n",
    "By 2013, the market had rebounded from the 2008 recession. Throughout the year, stock growth never stopped. I'll choose this year to test the model's performance in a successful market.\n",
    "\n",
    "These years will be removed from the training set when the time comes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stocks.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the stocks have been retrieved, I concatenate them into a single DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stock DataFrames are merged with the market DataFrame by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stocks.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finalized data is saved for future use. This step may be skipped in future iterations once you are satisfied with the size and quality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stocks.to_hdf('../data/raw/market_stocks.h5', key='top_stocks')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
